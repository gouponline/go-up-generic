This is gnugo.info, produced by makeinfo version 4.2 from gnugo.texi.

INFO-DIR-SECTION GNU games
START-INFO-DIR-ENTRY
* GNU go: (gnugo).          The GNU Go program
END-INFO-DIR-ENTRY


File: gnugo.info,  Node: Corner Matcher,  Prev: Ladders in Joseki,  Up: Patterns

Corner Matcher
==============

   GNU Go uses a special matcher for joseki patterns.  It has certain
constraints on the patterns it can match, but is much faster and takes
far less space to store patterns than the standard matcher.

   Patterns used with corner matcher have to qualify the following
conditions:

   * They must be matchable only at a corner of the board (hence the
     name of the matcher).

   * They can consist only of `O', `X' and `.' elements.

   * Of all pattern values (*note Pattern Values::), corner matcher only
     support `shape(x)'.  This is not because the matcher cannot handle
     other values in principle, just they are currently not used in
     joseki databases.

   Corner matcher was specifically designed for joseki patterns and
they of course satisfy all the conditions above.  With some
modifications corner matcher could be used for fuseki patterns as well,
but fullboard matcher does its work just fine.

   The main idea of the matcher is very same to the one of DFA matcher
(*note Pattern matching with DFA::): check all available patterns at
once, not a single pattern at a time.  A modified version of DFA
matcher could be used for joseki pattern matching, but its database
would be very large.  Corner matcher capitalizes on the fact that there
are relatively few stones in each such pattern.

   Corner pattern database is organized into a tree.  Nodes of the tree
are called "variations".  Variations represent certain sets of stones
in a corner of the board.  Root variation corresponds to an empty
corner and a step down the tree is equivalent to adding a stone to the
corner.  Each variation has several properties:

   - stone position relative to the corner,

   - a flag determining whether the stone color must be equal to the
     first matched stone color,

   - number of stones in the corner area (see below) of the variation
     stone.

   By corner area we define a rectangle which corners are the current
corner of the board and the position of the stone (inclusive).  For
instance, if the current board corner is A19 then corner area of a
stone at C18 consists of A18, A19, B18, B19, C18 and C19.

   Variation which is a direct child of the root variation matches if
there is any stone at the variation position and the stone is alone in
its corner area.

   Variation at a deeper level of the tree matches if there is a stone
of specified color in variation position and the number of stones in its
corner area is equal to the number specified in variation structure.

   When a certain variation matches, all its children has to be checked
recursively for a match.

   All leaf variations and some inner ones have patterns attached to
them.  For a pattern to match, it is required that its _parent_
variation matches.  In addition, it is checked that pattern is being
matched for the appropriate color (using its variation "stone color"
field) and that the number of stones in the area where the pattern is
being matched is indeed equal to the number of stones in the pattern.
The "stone position" property of the pattern variation determines the
move suggested by the pattern.

   Consider this joseki pattern which has four stones:

     ------+
     ......|
     ......|
     .O*...|
     .XXO..|
     ......|
     ......|

   To encode it for the corner matcher, we have to use five variations,
each next being a child of previous:

Tree level   Position   Color     Number of stones
1            R16        "same"    1
2            P17        "same"    1
3            Q16        "other"   2
4            P16        "other"   4
5            Q17        "same"    1

   The fifth variation should have an attached pattern.  Note that the
stone color for the fifth variation is "same" because the first matched
stone for this pattern is `O' which stands for the stones of the player
to whom moves are being suggested with `*'.

   The tree consists of all variations for all patterns combined
together.  Variations for each patterns are sorted to allow very quick
tree branch rejection and at the same time keep the database small
enough.  More details can be found in comments in file `mkpat.c'

   Corner matcher resides in `matchpat.c' in two functions:
`corner_matchpat()' and `do_corner_matchpat()'.  The former computes
`num_stones[]' array which holds number of stones in corner areas of
different intersections of the board for all possible transformations.
`corner_matchpat()' also matches top-level variations.
`do_corner_matchpat()' is responsible for recursive matching on the
variation tree and calling callback function upon pattern match.

   Tree-like database for corner matcher is generated by `mkpat'
program.  Database generator consists of several functions, most
important are: `corner_best_element()', `corner_variation_new()',
`corner_follow_variation()' and `corner_add_pattern()'.


File: gnugo.info,  Node: DFA,  Next: Utility Functions,  Prev: SGF,  Up: Top

The DFA pattern matcher
***********************

   In this chapter, we describe the principles of the gnugo DFA pattern
matcher.  The aim of this system is to permit a fast pattern matching
when it becomes time critical like in owl module (*Note The Owl
Code::). Since GNU Go 3.2, this is enabled by default. You can still
get back the traditional pattern matcher by running `configure
--disable-dfa' and then recompiling GNU Go.

   Otherwise, a finite state machine called a Deterministic Finite
State Automaton (*Note What is a DFA::) will be built off line from the
pattern database. This is used at runtime to speedup pattern matching
(*Note Pattern matching with DFA:: and *Note Incremental Algorithm::).
The runtime speedup is at the cost of an increase in memory use and
compile time.

* Menu:

* Introduction to the DFA::  Scanning the board along a path
* What is a DFA:: A recall of language theory.
* Pattern matching with DFA:: How to retrieve go patterns with a dfa ?
* Building the DFA:: Playing with explosives.
* Incremental Algorithm:: The joy of determinism.
* DFA Optimizations:: Some possible optimizations.


File: gnugo.info,  Node: Introduction to the DFA,  Next: What is a DFA,  Up: DFA

Introduction to the DFA
=======================

   The general idea is as follows:

   For each intersection of the board, its neighbourhood is scanned
following a predefined path.  The actual path used does not matter very
much; GNU Go uses a spiral as shown below.

       +---B--------------+
       | C 4 A . . . . . .|
       D 5 1 3 9 . . . . .|
       E 6 2 8 . . X . . .|
       | F 7 . . . . . . .|
       | . +-> . . . . . .|
       | . . . . . . . . .|
       | . O . . . X . . .|
       | . . . . . . . . .|
       | . . . . . . . . .|
       +------------------+

   In each step of the path, the pattern matcher jumps into a state
determined by what it has found on the board so far. If we have
successfully matched one or several patterns in this step, this state
immediately tells us so (in its "attribute").  But the state also
implicitly encodes which further patterns can still get matched: The
information stored in the state contains in which state to jump next,
depending on whether we find a black, white or empty intersection (or
an intersection out of board) in the next step of the path. The state
will also immediately tell us if we cannot find any further pattern (by
telling us to jump into the "error" state).

   These sloppy explanations may become clearer with the definitions in
the next section (*Note What is a DFA::).

   Reading the board following a predefined path reduces the two
dimentional pattern matching to a linear text searching problem.  For
example, this pattern

     ?X?
     .O?
     ?OO

scanned following the path

      B
     C4A
     5139
     628
      7

gives the string "OO?X.?*O*?*?"  where "?" means 'don't care' and "*"
means 'don't care, can even be out of board'.

   So we can forget that we are dealing with two dimensional patterns
and consider linear patterns.


File: gnugo.info,  Node: What is a DFA,  Next: Pattern matching with DFA,  Prev: Introduction to the DFA,  Up: DFA

What is a DFA
=============

   The acronym DFA means Deterministic Finite state Automaton (See
`http://www.eti.pg.gda.pl/~jandac/thesis/node12.html' or `Hopcroft &
Ullman "Introduction to Language Theory"' for more details).  DFA are
common tools in compilers design (Read `Aho, Ravi Sethi, Ullman
"COMPILERS: Principles, Techniques and Tools"' for a complete
introduction), a lot of powerfull text searching algorithm like
`Knuth-Morris-Pratt' or `Boyer-Moore' algorithms are based on DFA's
(See `http://www-igm.univ-mlv.fr/~lecroq/string/' for a bibliography of
pattern matching algorithms).

   Basically, a DFA is a set of "states" connected by labeled
"transitions".  The labels are the values read on the board, in gnugo
these values are EMPTY, WHITE, BLACK or OUT_BOARD, denoted respectively
by '.','O','X' and '#'.

   The best way to represent a dfa is to draw its transition graph: the
pattern "????..X" is recognized by the following DFA:

        .,X,O     .,X,O    .,X,O    .,X,O     .      .      X
     [1]------>[2]----->[3]----->[4]----->[5]--->[6]--->[7]--->[8 OK!]
     Start

   This means that starting from state [1], if you read '.','X' or 'O'
on the board, go to state [2] and so on until you reach state [5].
From state [5], if you read '.', go to state [6] otherwise go to error
state [0].  And so on until you reach state [8].  As soon as you reach
state [8], you recognize Pattern "????..X"

   Adding a pattern like "XXo" ('o' is a wildcard for not 'X') will
transform directly the automaton by synchronization product (*Note
Building the DFA::).  Consider the following DFA:

     Start .,O   .,X,O    .,O,X   .,X,O      .      .       X
     [1]---->[2]----->[3]----->[4]------>[5]--->[6]---->[7]--->[8 OK!]
      |                ^        ^         ^
      |            .,O |        |         |
      |            ----         |         |
      |           |          X  |         |
      |           |          ---    .,X,O |
      |           |         |             |
      |     X     |   X     | O,.         |
       --------->[9]------>[A]--->[B OK!]-

   By adding a special "error" state and completing each state by a
transition to error state when there is none, we transform easily a DFA
in a "Complete Deterministic Finite state Automaton" (CDFA).  The
synchronization product (*Note Building the DFA::) is only possible on
CDFA's.

     Start .,O   .,X,O    .,O,X   .,X,O      .      .       X
     [1]---->[2]----->[3]----->[4]------>[5]--->[6]---->[7]--->[8 OK!]
      |                ^        ^         ^      |       |      |
      |            .,O |        |         |      |       |      |
      |            ----         |         |      |       |      |
      |           |          X  |         |      |X,O    | .,O  |X,.,O
      |           |          ---    .,X,O |      |       |      |
      |           |         |             |      |       |      |
      |     X     |   X     | O,.         |     \ /     \ /    \ /
       --------->[9]------>[A]--->[B OK!]-      [0  Error state !]

   The graph of a CDFA is coded by an array of states: The 0 state is
the "error" state and the start state is 1.

     ----------------------------------------------------
      state  |   .    |   O    |   X    |   #    |  att
     ----------------------------------------------------
           1 |      2 |      2 |      9 |      0 |
           2 |      3 |      3 |      3 |      0 |
           3 |      4 |      4 |      4 |      0 |
           5 |      6 |      0 |      0 |      0 |
           6 |      7 |      0 |      0 |      0 |
           7 |      0 |      0 |      8 |      0 |
           8 |      0 |      0 |      0 |      0 | Found pattern "????..X"
           9 |      3 |      3 |      A |      0 |
           A |      B |      B |      4 |      0 |
           B |      5 |      5 |      5 |      0 | Found pattern "XXo"
     ----------------------------------------------------

   To each state we associate an often empty list of attributes which
is the list of pattern indexes recognized when this state is reached.
In '`dfa.h'' this is basically represented by two stuctures:

     `
     /* dfa state */
     typedef struct state
     {
       int next[4]; /* transitions for EMPTY, BLACK, WHITE and OUT_BOARD */
       attrib_t *att;
     }
     state_t;
     
     /* dfa */
     typedef struct dfa
     {
       attrib_t *indexes; /* Array of pattern indexes */
       int maxIndexes;
     
       state_t *states; /* Array of states */
       int maxStates;
     }
     dfa_t;'


File: gnugo.info,  Node: Pattern matching with DFA,  Next: Building the DFA,  Prev: What is a DFA,  Up: DFA

Pattern matching with DFA
=========================

   Recognizing with a DFA is very simple and thus very fast (See
'`scan_for_pattern()'' in the '`engine/matchpat.c'' file).

   Starting from the start state, we only need to read the board
following the spiral path, jump from states to states following the
transitions labelled by the values read on the board and collect the
patterns indexes on the way.  If we reach the error state (zero), it
means that no more patterns will be matched.  The worst case complexity
of this algorithm is o(m) where m is the size of the biggest pattern.

   Here is an example of scan:

   First we build a minimal dfa recognizing these patterns: "X..X",
"X???", "X.OX" and "X?oX".  Note that wildcards like '?','o', or 'x'
give multiple out-transitions.

     ----------------------------------------------------
      state  |   .    |   O    |   X    |   #    |  att
     ----------------------------------------------------
           1 |      0 |      0 |      2 |      0 |
           2 |      3 |     10 |     10 |      0 |
           3 |      4 |      7 |      9 |      0 |
           4 |      5 |      5 |      6 |      0 |
           5 |      0 |      0 |      0 |      0 |    2
           6 |      0 |      0 |      0 |      0 |    4    2    1
           7 |      5 |      5 |      8 |      0 |
           8 |      0 |      0 |      0 |      0 |    4    2    3
           9 |      5 |      5 |      5 |      0 |
          10 |     11 |     11 |      9 |      0 |
          11 |      5 |      5 |     12 |      0 |
          12 |      0 |      0 |      0 |      0 |    4    2
     ----------------------------------------------------

   We perform the scan of the string "X..XXO...." starting from state 1:

   Current state:     1, substring to scan : X..XXO....

   We read an 'X' value, so from state 1 we must go to state 2.

   Current state:     2, substring to scan : ..XXO....

   We read a '.' value, so from state 2 we must go to state 3 and so on
...

     Current state:     3, substring to scan : .XXO....
     Current state:     4, substring to scan : XXO....
     Current state:     6, substring to scan : XO....
     Found pattern 4
     Found pattern 2
     Found pattern 1

   After reaching state 6 where we match patterns 1,2 and 4, there is
no out-transitions so we stop the matching.  To keep the same match
order as in the standard algorithm, the patterns indexes are collected
in an array and sorted by indexes.


File: gnugo.info,  Node: Building the DFA,  Next: Incremental Algorithm,  Prev: Pattern matching with DFA,  Up: DFA

Building the DFA
================

   The most flavouring point is the building of the minimal DFA
recognizing a given set of patterns.  To perform the insertion of a new
pattern into an already existing DFA one must completly rebuild the
DFA: the principle is to build the minimal CDFA recognizing the new
pattern to replace the original CDFA with its "synchronised product" by
the new one.

   We first give a formal definition: Let L be the left CDFA and R be
the right one.  Let B be the "synchronised product" of L by R.  Its
states are the couples (l,r) where l is a state of L and r is a state
of R.  The state (0,0) is the error state of B and the state (1,1) is
its initial state.  To each couple (l,r) we associate the union of
patterns recognized in both l and r.  The transitions set of B is the
set of transitions (l1,r1)--a-->(l2,r2) for each symbol 'a' such that
both l1--a-->l2 in L and r1--a-->r2 in R.

   The maximal number of states of B is the product of the number of
states of L and R but almost all this states are non reachable from the
initial state (1,1).

   The algorithm used in function '`sync_product()'' builds the minimal
product DFA only by keeping the reachable states.  It recursively scans
the product CDFA by following simultaneously the transitions of L and
R. A hast table (`gtest') is used to check if a state (l,r) has already
been reached, the reachable states are remapped on a new DFA. The CDFA
thus obtained is minimal and recognizes the union of the two patterns
sets.

   It is possible to construct a special pattern database that
generates an "explosive" automaton: the size of the DFA is in the worst
case exponential in the number of patterns it recognizes.  But it
doesn't occur in pratical situations: the dfa size tends to be
"stable".  By "stable" we mean that if we add a pattern which greatly
increases the size of the dfa it also increases the chance that the
next added pattern does not increase its size at all.  Nevertheless
there are many ways to reduce the size of the DFA. Good compression
methods are explained in `Aho, Ravi Sethi, Ullman "COMPILERS:
Principles, Techniques and Tools" chapter Optimization of DFA-based
pattern matchers'.


File: gnugo.info,  Node: Incremental Algorithm,  Next: DFA Optimizations,  Prev: Building the DFA,  Up: DFA

Incremental Algorithm
=====================

   The incremental version of the DFA pattern matcher is not yet
implemented in gnugo but we explain here how it will work.  By
definition of a deterministic automaton, scanning the same string will
reach the same states every time.

   Each reached state during pattern matching is stored in a stack
`top_stack[i][j]' and `state_stack[i][j][stack_idx]' We use one stack
by intersection `(i,j)'.  A precomputed reverse path list allows to
know for each couple of board intersections `(x,y)' its position
`reverse(x,y)' in the spiral scan path starting from `(0,0)'.

   When a new stone is put on the board at `(lx,ly)', the only work of
the pattern matcher is:

     `
      for(each stone on the board at (i,j))
         if(reverse(lx-i,ly-j) < top_stack[i][j])
           {
              begin the dfa scan from the state
              state_stack[i][j][reverse(lx-i,ly-j)];
           }
     '

   In most situations reverse(lx-i,ly-j) will be inferior to
top_stack[i][j]. This should speedup a lot pattern matching.


File: gnugo.info,  Node: DFA Optimizations,  Prev: Incremental Algorithm,  Up: DFA

Some DFA Optimizations
======================

   The dfa is constructed to minimize jumps in memory making some
assumptions about the frequencies of the values: the EMPTY value is
supposed to appear often on the board, so the the '.'  transition are
almost always successors in memory.  The OUT_BOARD are supposed to be
rare, so '#' transitions will almost always imply a big jump.


File: gnugo.info,  Node: Tactical Reading,  Next: Pattern Based Reading,  Prev: Patterns,  Up: Top

Tactical reading
****************

   The process of visualizing potential moves done by you and your
opponent to learn the result of different moves is called "reading".
GNU Go does three distinct types of reading: "tactical reading" which
typically is concerned with the life and death of individual strings,
"Owl reading" which is concerned with the life and death of dragons,
and "connection reading".  In this Chapter, we document the tactical
reading code, which is in `engine/reading.c'.

* Menu:

* Reading Basics::               Reading Basics
* Hashing::                      Hashing of positions
* Persistent Cache::             Persistent Reading Cache
* Ko::                           Ko handling
* A Ko Example::                 A Ko Example
* Another Ko Example::           Another Ko Example
* Alternate Komaster Schemes::   Alternate Komaster Schemes
* Superstrings::                 Superstrings
* Debugging::                    Debugging the reading code
* Connection Reading::           Connection Reading


File: gnugo.info,  Node: Reading Basics,  Next: Hashing,  Up: Tactical Reading

Reading Basics
==============

   What we call _Tactical Reading_ is the analysis whether there is a
direct capture of a single string, or whether there is a move to prevent
such a direct capture.

   If the reading module finds out that the string can get captured,
this answer should (usually) be trusted. However, if it says it can be
defended, this does not say as much. It is often the case that such a
string has no chance to make a life, but that it cannot be captured
within the horizon (and the cutoff heuristics) of the tactical reading.

   The tactical reading is done by the functions in `engine/reading.c'.
It is a minimax search that declares win for the attacker once he can
physically take the string off board, whereas the defense is considered
successful when the string has sufficiently many liberties. A string
with five liberties is always considered alive. At higher depth within
the search tree even fewer liberties cause GNU Go to give up the attack,
*Note depthparams::.

   The reading code makes use of a stack onto which board positions can
be pushed. The parameter `stackp' is zero if GNU Go is examining the
true board position; if it is higher than zero, then GNU Go is
examining a hypothetical position obtained by playing several moves.

   The most important public reading functions are `attack' and
`find_defense'. These are wrappers for functions `do_attack' and
`do_find_defense' which are declared statically in `reading.c'. The
functions `do_attack' and `do_find_defense' call each other recursively.

Organization of the reading code
--------------------------------

   The function `do_attack' and `do_find_defense' are wrappers
themselves and call `attack1', `attack2', `attack3' or `attack4' resp.
`defend1', `defend1', `defend1' or `defend1' depending on the number of
liberties.

   These are fine-tuned to generate and try out the moves in an
efficient order. They generate a few moves themselves (mostly direct
liberties of the string), and then call helper functions called
`..._moves' which suggest less obvious moves. Which of these functions
get called depends on the number of liberties and of the current search
depth.

Return Codes
------------

   The return codes of the reading (and owl) functions and owl can be
`0', `KO_B', `KO_A' or `WIN'. Each reading function determines whether
a particular player (assumed to have the move) can solve a specific
problem, typically attacking or defending a string.

   A return code of `WIN' means success, 0 failure, while `KO_A' and
`KO_B' are success conditioned on ko. A function returns `KO_A' if the
position results in ko and that the player to move will get the first
ko capture (so the opponent has to make the first ko threat). A return
code of `KO_B' means that the player to move will have to make the
first ko threat.

   If GNU Go is compiled with the configure option
`--enable-experimental-owl-ext' then the owl functions also have
possible return codes of `GAIN' and `LOSS'. A code of `GAIN' means that
the attack (or defense) does not succeed, but that in the process of
trying to attack or defend, an opponent's worm is captured. A code of
`LOSS' means that the attack or defense succeeds, but that another
friendly worm dies during the attack or defense.

Reading cutoff and depth parameters
-----------------------------------

   Depth of reading is controlled by the parameters `depth' and
`branch_depth'. The `depth' has a default value `DEPTH' (in
`liberty.h'), which is set to 16 in the distribution, but it may also
be set at the command line using the `-D' or `--depth' option.  If
`depth' is increased, GNU Go will be stronger and slower. GNU Go will
read moves past depth, but in doing so it makes simplifying assumptions
that can cause it to miss moves.

   Specifically, when `stackp > depth', GNU Go assumes that as soon as
the string can get 3 liberties it is alive. This assumption is
sufficient for reading ladders.

   The `branch_depth' is typically set a little below `depth'.  Between
`branch_depth' and `depth', attacks on strings with 3 liberties are
considered, but branching is inhibited, so fewer variations are
considered.

   %%Currently the reading code does not try to defend a string by
%attacking a boundary string with more than two liberties. Because %of
this restriction, it can make oversights. A symptom of this is %two
adjacent strings, each having three or four liberties, each %classified
as `DEAD'. To resolve such situations, a function %`small_semeai()' (in
`engine/semeai.c') looks for such %pairs of strings and corrects their
classification.

   The `backfill_depth' is a similar variable with a default 12. Below
this depth, GNU Go will try "backfilling" to capture stones.  For
example in this situation:


     .OOOOOO.    on the edge of the board, O can capture X but
     OOXXXXXO    in order to do so he has to first play at a in
     .aObX.XO    preparation for making the atari at b. This is
     --------    called backfilling.

   Backfilling is only tried with `stackp <= backfill_depth'. The
parameter `backfill_depth' may be set using the `-B' option.

   The `fourlib_depth' is a parameter with a default of only 7.  Below
this depth, GNU Go will try to attack strings with four liberties. The
`fourlib_depth' may be set using the `-F' option.

   The parameter `ko_depth' is a similar cutoff. If `stackp<ko_depth',
the reading code will make experiments involving taking a ko even if it
is not legal to do so (i.e., it is hypothesized that a remote ko threat
is made and answered before continuation).  This parameter may be set
using the `-K' option.

   * `int attack(int str, int *move)'

          Determines if the string at `str' can be attacked, and if so,
          `*move' returns the attacking move, unless `*movei' is a null
          pointer. (Use null pointers if you are interested in the
          result of the attack but not the attacking move itself.)
          Returns `WIN', if the attack succeeds, 0 if it fails, and
          `KO_A' or `KO_B' if the result depends on ko *Note Return
          Codes::.

   * `find_defense(int str, int *move)'

          Attempts to find a move that will save the string at `str'. It
          returns true if such a move is found, with `*move' the
          location of the saving move (unless `*move' is a null
          pointer). It is not checked that tenuki defends, so this may
          give an erroneous answer if `!attack(str)'.  Returns `KO_A'
          or `KO_B' if the result depends on ko *Note Return Codes::.

   * `safe_move(int str, int color)' :

          The function `safe_move(str, color)' checks whether a move at
          `str' is illegal or can immediately be captured. If
          `stackp==0' the result is cached. If the move only can be
          captured by a ko, it's considered safe. This may or may not
          be a good convention.


File: gnugo.info,  Node: Hashing,  Next: Persistent Cache,  Prev: Reading Basics,  Up: Tactical Reading

Hashing of Positions
====================

   To speed up the reading process, we note that a position can be
reached in several different ways.  In fact, it is a very common
occurrence that a previously checked position is rechecked, often
within the same search but from a different branch in the recursion
tree.

   This wastes a lot of computing resources, so in a number of places,
we store away the current position, the function we are in, and which
worm is under attack or to be defended.  When the search for this
position is finished, we also store away the result of the search and
which move made the attack or defense succeed.

   All this data is stored in a hash table, sometimes also called a
transposition table, where Go positions are the key and results of the
reading for certain functions and groups are the data. You can increase
the size of the Hash table using the `-M' or `--memory' option *note
Invoking GNU Go::.

   The hash table is created once and for all at the beginning of the
game by the function `hashtable_new()'. Although hash memory is thus
allocated only once in the game, the table is reinitialized at the
beginning of each move by a call to `hashtable_clear()' from
`genmove()'.

* Menu:

* Hash Calculation::            Calculation of the hash value
* Hash Organization::           Organization of the hash table
* Hash Structures::             Structures in `hash.h'


File: gnugo.info,  Node: Hash Calculation,  Next: Hash Organization,  Up: Hashing

Calculation of the hash value
-----------------------------

   The hash algorithm is called Zobrist hashing, and is a standard
technique for go and chess programming. The algorithm as used by us
works as follows:

  1. First we define a "go position".  This positions consists of
        * the actual board, i.e. the locations and colors of the stones

        * A "ko point", if a ko is going on.  The ko point is defined as
          the empty point where the last single stone was situated
          before it was captured.

     It is not necessary to specify the color to move (white or black)
     as part of the position. The reason for this is that read results
     are stored separately for the various reading functions such as
     `attack3', and it is implicit in the calling function which player
     is to move.

  2. For each location on the board we generate random numbers:
        * A number which is used if there is a white stone on this
          location

        * A number which is used if there is a black stone on this
          location

        * A number which is used if there is a ko on this location

     These random numbers are generated once at initialization time and
     then used throughout the life time of the hash table.

  3. The hash key for a position is the XOR of all the random numbers
     which are applicable for the position (white stones, black stones,
     and ko position).


File: gnugo.info,  Node: Hash Organization,  Next: Hash Structures,  Prev: Hash Calculation,  Up: Hashing

Organization of the hash table
------------------------------

   The hash table consists of 3 parts:

   * An area which contains so called "Hash Nodes". Each hash node
     contains:
        - A go position as defined above.

        - A computed hash value for the position

        - A pointer to Read Results (see below)

        - A pointer to another hash node.

   * An area with so called Read Results.  These are used to store
     which function was called in the go position, which string was
     under attack or to be defended, and the result of the reading.

     Each Read Result contains:
        - the function ID (an int between 0 and 255), the position of
          the string under attack and a depth value, which is used to
          determine how deep the search was when it was made, packed
          into one 32 bit integer.

        - The result of the search (a numeric value) and a position to
          play to get the result packed into one 32 bit integer.

        - A pointer to another Read Result.

   * An array of pointers to hash nodes.  This is the hash table proper.


   When the hash table is created, these 3 areas are allocated using
`malloc()'.  When the hash table is populated, all contents are taken
from the Hash nodes and the Read results. No further allocation is done
and when all nodes or results are used, the hash table is full.
Nothing is deleted from the hash table except when it is totally
emptied, at which point it can be used again as if newly initialized.

   When a function wants to use the hash table, it looks up the current
position using `hashtable_search()'. If the position doesn't already
exist there, it can be entered using

   `hashtable_enter_position()'.

   Once the function has a pointer to the hash node containing a
function, it can search for a result of a previous search using
`hashnode_search()'.  If a result is found, it can be used, and if not,
a new result can be entered after a search using
`hashnode_new_result()'.

   Hash nodes which hash to the same position in the hash table
(collisions) form a simple linked list.  Read results for the same
position, created by different functions and different attacked or
defended strings also form a linked list.

   This is deemed sufficiently efficient for now, but the representation
of collisions could be changed in the future.  It is also not
determined what the optimum sizes for the hash table, the number of
positions and the number of results are.


File: gnugo.info,  Node: Hash Structures,  Prev: Hash Organization,  Up: Hashing

Hash Structures
---------------

   The basic hash structures are declared in `engine/hash.h' and
`engine/cache.c'

     typedef struct hashposition_t {
       Compacttype  board[COMPACT_BOARD_SIZE];
       int          ko_pos;
     } Hashposition;

   Represents the board and optionally the location of a ko, which is
an illegal move. The player whose move is next is not recorded.

     typedef struct {
       Hashvalue     hashval;
       Hashposition  hashpos;
     } Hash_data;

   Represents the return value of a function (`hashval') and the board
state (`hashpos').

     typedef struct read_result_t {
       unsigned int data1;
       unsigned int data2;
     
       struct read_result_t *next;
     } Read_result;

   The data1 field packs into 32 bits the following fields:


     komaster:  2 bits (EMPTY, BLACK, WHITE, or GRAY)
     kom_pos : 10 bits (allows MAX_BOARD up to 31)
     routine :  4 bits (currently 10 different choices)
     str1    : 10 bits
     stackp  :  5 bits

   The data2 field packs into 32 bits the following fields:


     status :   2 bits (0 free, 1 open, 2 closed)
     result1:   4 bits
     result2:   4 bits
     move   :  10 bits
     str2   :  10 bits

   The `komaster' and `(kom_pos)' field are documented in *Note Ko::.

   When a new result node is created, 'status' is set to 1 'open'.
This is then set to 2 'closed' when the result is entered. The main use
for this is to identify open result nodes when the hashtable is
partially cleared. Another potential use for this field is to identify
repeated positions in the reading, in particular local double or triple
kos.

     typedef struct hashnode_t {
       Hash_data            key;
       Read_result        * results;
       struct hashnode_t  * next;
     } Hashnode;

   The hash table consists of hash nodes.  Each hash node consists of
The hash value for the position it holds, the position itself and the
actual information which is purpose of the table from the start.

   There is also a pointer to another hash node which is used when the
nodes are sorted into hash buckets (see below).

     typedef struct hashtable {
       size_t         hashtablesize;	/* Number of hash buckets */
       Hashnode    ** hashtable;	/* Pointer to array of hashnode lists */
     
       int            num_nodes;	/* Total number of hash nodes */
       Hashnode     * all_nodes;	/* Pointer to all allocated hash nodes. */
       int            free_node;	/* Index to next free node. */
     
       int            num_results;	/* Total number of results */
       Read_result  * all_results;	/* Pointer to all allocated results. */
       int            free_result;	/* Index to next free result. */
     } Hashtable;

   The hash table consists of three parts:

   * The hash table proper: a number of hash buckets with collisions
     being handled by a linked list.

   * The hash nodes.  These are allocated at creation time and are
     never removed or reallocated in the current implementation.

   * The results of the searches.  Since many different searches can be
     done in the same position, there should be more of these than hash
     nodes.


File: gnugo.info,  Node: Persistent Cache,  Next: Ko,  Prev: Hashing,  Up: Tactical Reading

Persistent Reading Cache
========================

   Some calculations can be safely saved from move to move. If the
opponent's move is not close to our worm or dragon, we do not have to
reconsider the life or death of that group on the next move. So the
result is saved in a persistent cache. Persistent caches are used for
are used in the engine for several types of read results.

   * Tactical reading

   * Owl reading

   * Connection reading

   * Breakin code

   In this section we will discuss the persistent caching of tactical
reading but the same principles apply to the other persistent caches.

   Persistent caching is an important performance feature. However it
can lead to mistakes and debugging problems--situations where GNU Go
generates the right move during debugging but plays a wrong move during
a game. If you suspect a persistent cache effect you may try loading
the sgf file with the `--replay' option and see if the mistake is
repeated (*note Invoking GNU Go::).

   The function `store_persistent_cache()' is called only by `attack'
and `find_defense', never from their static recursive counterparts
`do_attack' and `do_defend'.  The function
`store_persistent_reading_cache()' attempts to cache the most expensive
reading results. The function `search_persistent_reading_cache'
attempts to retrieve a result from the cache.

   If all cache entries are occupied, we try to replace the least useful
one. This is indicated by the score field, which is initially the
number of nodes expended by this particular reading, and later
multiplied by the number of times it has been retrieved from the cache.

   Once a (permanent) move is made, a number of cache entries
immediately become invalid.  These are cleaned away by the function
`purge_persistent_reading_cache().' To have a criterion for when a
result may be purged, the function `store_persistent_cache()' computes
the "reading shadow" and "active area". If a permanent move is
subsequently played in the active area, the cached result is
invalidated. We now explain this algorithm in detail.

   The "reading shadow" is the concatenation of all moves in all
variations, as well as locations where an illegal move has been tried.

   Once the read is finished, the reading shadow is expanded to the
"active area" which may be cached. The intention is that as long as no
stones are played in the active area, the cached value may safely be
used.

   Here is the algorithm used to compute the active area.  This
algorithm is in the function `store_persistent_reading_cache()'.  The
most expensive readings so far are stored in the persistent cache.

   * The reading shadow and the string under attack are marked with the
     character `1'. We also include the successful move, which is most
     often a part of the reading shadow, but sometimes not, for example
     with the function `attack1()'.

   * Next the reading shadow is expanded by marking strings and empty
     vertices adjacent to the area marked `1' with the character `2'.

   * Next vertices adjacent to empty vertices marked `2' are labelled
     with the character `3'.

   * Next all vertices adjacent to previously marked vertices. These are
     marked `-1' instead of the more logical `4' because it is slightly
     faster to code this way.

   * If the stack pointer is >0 we add the moves already played from the
     moves stack with mark 4.


File: gnugo.info,  Node: Ko,  Next: A Ko Example,  Prev: Persistent Cache,  Up: Tactical Reading

Ko Handling
===========

   The principles of ko handling are the same for tactical reading and
owl reading.

   We have already mentioned (*note Reading Basics::) that GNU Go uses
a return code of `KO_A' or `KO_B' if the result depends on ko. The
return code of `KO_B' means that the position can be won provided the
player whose move calls the function can come up with a sufficiently
large ko threat. In order to verify this, the function must simulate
making a ko threat and having it answered by taking the ko even if it
is illegal. We call such an experimental taking of the ko a
"conditional" ko capture.

   Conditional ko captures are accomplished by the function `tryko()'.
This function is like `trymove()' except that it does not require
legality of the move in question.

   The static reading functions, and the global functions `do_attack'
and `do_find_defense' have arguments `komaster', `kom_pos'. These
mediate ko captures to prevent the occurrence of infinite loops.

   Normally `komaster' is `EMPTY' but it can also be `BLACK', `WHITE'
or `GRAY'. The komaster is set to `color' when `color' makes a
conditional ko capture. In this case `kom_pos' is set to the location
of the captured ko stone.

   If the opponent is komaster, the reading functions will not try to
take the ko at `kom_pos'. Also, the komaster is normally not allowed to
take another ko. The exception is a nested ko, characterized by the
condition that the captured ko stone is at distance 1 both vertically
and horizontally from `kom_pos', which is the location of the last
stone taken by the komaster. Thus in this situation:


              .OX
              OX*X
             OmOX
              OO

   Here if `m' is the location of `kom_pos', then the move at `*' is
allowed.

   The rationale behind this rule is that in the case where there are
two kos on the board, the komaster cannot win both, and by becoming
komaster he has already chosen which ko he wants to win. But in the
case of a nested ko, taking one ko is a precondition to taking the
other one, so we allow this.

   If the komaster's opponent takes a ko, then both players have taken
one ko. In this case `komaster' is set to `GRAY' and after this further
ko captures are not allowed.

   If the ko at `kom_pos' is filled, then the komaster reverts to
`EMPTY'.

   Several different komaster schemes may be found in `board.c'.  The
komaster scheme used in GNU Go 3.0 was known as komaster scheme 1.  It
may be summarized as follows. It is assumed that `O' is about to move.

   * 1. Komaster is `EMPTY'.
        - 1a) Unconditional ko capture is allowed. Komaster remains
          `EMPTY'.

        - 1b) Conditional ko capture is allowed. Komaster is set to `O'
          and `kom_pos' to the location of the ko, where a stone was
          just removed.

   * 2. Komaster is `O':
        - 2a) Only nested ko captures are allowed.

        - 2b) If komaster fill the ko at `kom_pos' then komaster
          reverts to `EMPTY'.

   * 3. Komaster is `X':
        - Play at `kom_pos' is not allowed. Any other ko capture is
          allowed. If `O' takes another ko, komaster becomes `GRAY'.

   * 4. Komaster is `GRAY':
        - Ko captures are not allowed. If the ko at `kom_pos' is filled
          then the komaster reverts to `EMPTY'.

   In GNU Go 3.2 and 3.4 komaster scheme 5 is used. It may be described
as follows.

   * 1. Komaster is EMPTY.
        - 1a. Unconditional ko capture is allowed.

               Komaster remains EMPTY if previous move was not a ko
               capture.  Komaster is set to WEAK_KO if previous move
               was a ko capture and kom_pos is set to the old value of
               board_ko_pos.

        - 1b) Conditional ko capture is allowed.

               Komaster is set to O and kom_pos to the location of the
               ko, where a stone was just removed.

   * 2. Komaster is O:
        - 2a) Only nested ko captures are allowed. Kom_pos is moved to
          the new removed stone.

        - 2b) If komaster fills the ko at kom_pos then komaster reverts
          to EMPTY.

   * 3. Komaster is X:

          Play at kom_pos is not allowed. Any other ko capture is
          allowed. If O takes another ko, komaster becomes GRAY_X.

   * 4. Komaster is GRAY_O or GRAY_X:

          Ko captures are not allowed. If the ko at kom_pos is filled
          then the komaster reverts to EMPTY.

   * 5. Komaster is WEAK_KO:
        - 5a) After a non-ko move komaster reverts to EMPTY.

        - 5b) Unconditional ko capture is only allowed if it is nested
          ko capture.

               Komaster is changed to WEAK_X and kom_pos to the old
               value of board_ko_pos.

        - 5c) Conditional ko capture is allowed according to the rules
          of 1b.


File: gnugo.info,  Node: A Ko Example,  Next: Another Ko Example,  Prev: Ko,  Up: Tactical Reading

A Ko Example
============

   To see the komaster scheme in action, consider this position from
the file `regressions/games/life_and_death/tripod9.sgf'.  We recommend
studying this example by examining the variation file produced by the
command:

       gnugo -l tripod9.sgf --decide-dragon C3 -o vars.sgf

   In the lower left hand corner, there are kos at A2 and B4.  Black is
unconditionally dead because if W wins either ko there is nothing B can
do.


      8 . . . . . . . .
      7 . . O . . . . .
      6 . . O . . . . .
      5 O O O . . . . .
      4 O . O O . . . .
      3 X O X O O O O .
      2 . X X X O . . .
      1 X O . . . . . .
        A B C D E F G H

   This is how the komaster scheme sees this. B (i.e. X) starts by
taking the ko at B4. W replies by taking the ko at A1. The board looks
like this:


      8 . . . . . . . .
      7 . . O . . . . .
      6 . . O . . . . .
      5 O O O . . . . .
      4 O X O O . . . .
      3 X . X O O O O .
      2 O X X X O . . .
      1 . O . . . . . .
        A B C D E F G H

   Now any move except the ko recapture (currently illegal) at A1 loses
for B, so B retakes the ko and becomes komaster.  The board looks like
this:


      8 . . . . . . . .         komaster: BLACK
      7 . . O . . . . .         kom_pos: A2
      6 . . O . . . . .
      5 O O O . . . . .
      4 O X O O . . . .
      3 X . X O O O O .
      2 . X X X O . . .
      1 X O . . . . . .
        A B C D E F G H

   W takes the ko at B3 after which the komaster is `GRAY' and ko
recaptures are not allowed.


      8 . . . . . . . .         komaster: GRAY
      7 . . O . . . . .         kom_pos: B4
      6 . . O . . . . .
      5 O O O . . . . .
      4 O . O O . . . .
      3 X O X O O O O .
      2 . X X X O . . .
      1 X O . . . . . .
        A B C D E F G H

   Since B is not allowed any ko recaptures, there is nothing he can do
and he is found dead. Thus the komaster scheme produces the correct
result.


File: gnugo.info,  Node: Another Ko Example,  Next: Alternate Komaster Schemes,  Prev: A Ko Example,  Up: Tactical Reading

Another Ko Example
==================

   We now consider an example to show why the komaster is reset to
`EMPTY' if the ko is resolved in the komaster's favor. This means that
the ko is filled, or else that is becomes no longer a ko and it is
illegal for the komaster's opponent to play there.

   The position resulting under consideration is in the file
`regressions/games/ko5.sgf'.  This is the position:

      . . . . . . O O 8
      X X X . . . O . 7
      X . X X . . O . 6
      . X . X X X O O 5
      X X . X . X O X 4
      . O X O O O X . 3
      O O X O . O X X 2
      . O . X O X X . 1
      F G H J K L M N

   We recommend studying this example by examining the variation file
produced by the command:

     gnugo -l ko5.sgf --quiet --decide-string L1 -o vars.sgf

   The correct resolution is that H1 attacks L1 unconditionally while K2
defends it with ko (code `KO_A').

   After Black (X) takes the ko at K3, white can do nothing but retake
the ko conditionally, becoming komaster. B cannot do much, but in one
variation he plays at K4 and W takes at H1. The following position
results:

      . . . . . . O O 8
      X X X . . . O . 7
      X . X X . . O . 6
      . X . X X X O O 5
      X X . X X X O X 4
      . O X O O O X . 3
      O O X O . O X X 2
      . O O . O X X . 1
      F G H J K L M N

   Now it is important the `O' is no longer komaster. Were `O' still
komaster, he could capture the ko at N3 and there would be no way to
finish off B.

